{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "%load_ext jupyternotify\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from data import dataset\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k(model, input_, top=3):\n",
    "    probs = torch.softmax(model(Variable(input_)), dim=1)\n",
    "    top_probs, top_labs = probs.topk(top)\n",
    "    top_probs = top_probs.detach().numpy().tolist()[0] \n",
    "    top_labs = top_labs.detach().numpy().tolist()[0]\n",
    "    top_labels = [data['classes'][lab] for lab in top_labs]\n",
    "    input, label = next(iter(data['test']))\n",
    "    \n",
    "    out = ''\n",
    "    for prob, label in zip(top_probs, top_labels):\n",
    "        out += label + '->' + str(round(prob, 2)) + \"\\n\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    'Function that plots an images'\n",
    "    \n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images, data, class_names):\n",
    "    '''\n",
    "    Function that takes a batch of the dataset and plot them with the prediction\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    model -> Model that will be used to predict the images\n",
    "    num_images -> Num of images that will be ploted\n",
    "    data -> Data that will be used to visualize the predictions of the model\n",
    "    class_names -> Dictionary that maps a number to a class of the model\n",
    "    '''\n",
    "    \n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(data):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            class_ = Variable(labels)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {0} \\n correct: {1} \\n Top 3:\\n {2}'.format(class_names[preds.item()], class_names[class_.item()],  top_k(model, inputs, top=3)) )\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, data):\n",
    "    '''\n",
    "    Function that measures the accuracy of a model\n",
    "    \n",
    "    Parameters\n",
    "        model -> The model to be evaluated.\n",
    "        data -> The data that will be used to evaluate the model.\n",
    "    '''\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    for x, y in data:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            y = y.view(-1, 1).type(torch.LongTensor)\n",
    "            x_var = Variable(x)\n",
    "            scores = model(x_var)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "        \n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        \n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    \n",
    "    return int(100 * acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(model, data, classes):\n",
    "    '''\n",
    "    Function that measures the accuracy of a model per class\n",
    "    \n",
    "    Parameters\n",
    "        model -> The model to be evaluated.\n",
    "        data -> The data that will be used to evaluate the model.\n",
    "        classes -> Dictionary that maps a number to a class of the model\n",
    "    '''\n",
    "     \n",
    "    model.eval()\n",
    "    confusion_matrix = torch.zeros(len(classes), len(classes))\n",
    "\n",
    "    _classes = []\n",
    "    _preds = []\n",
    "    predicted_labels = []\n",
    "    loocv_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(data):\n",
    "            \n",
    "            tmp_labels = model(inputs)\n",
    "            classes_list = labels.cpu().detach().numpy().tolist()\n",
    "            _classes[:]=[i+1 for i in classes_list]\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            gpu_tensor_probs = F.softmax(outputs, 1)\n",
    "            cpu_numpy_probs = gpu_tensor_probs.data.cpu().numpy()\n",
    "            loocv_probs.append(cpu_numpy_probs.tolist())\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds_list = preds.cpu().detach().numpy().tolist()\n",
    "            _preds[:]=[i+1 for i in preds_list]\n",
    "\n",
    "            predicted_labels.append(preds.cpu().detach().numpy().tolist())\n",
    "            for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    for i in range(0, len(classes)):\n",
    "        total = int(confusion_matrix.sum(dim=1)[i].numpy())\n",
    "        correct = int(confusion_matrix[i][i].numpy())\n",
    "        acc = (confusion_matrix.diag()/confusion_matrix.sum(1))[i]*100\n",
    "        class_ = classes[i]\n",
    "        print(F'Class {class_} --> accuracy: {round(acc.item(), 2)}, correct predictions: {correct}, all: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset('artist', bs_train=1, bs_test=1, bs_valid=1)\n",
    "num_classes = len(data['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = True\n",
    "model = models.alexnet(pretrained=trained)\n",
    "model_type = type(model).__name__\n",
    "print (model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trained:\n",
    "    print (\"Freezing layers\")\n",
    "    for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "last_layer = None\n",
    "if model_type == 'AlexNet':\n",
    "    num_ftrs = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "    last_layer = model.classifier[6]\n",
    "elif model_type == 'ResNet':\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    last_layer = model.fc\n",
    "    \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading a trained model\n",
    "name = 'AlexNet_True_artist_t10_v5_c10_acc74_min4'\n",
    "nn_dict = torch.load(F\"{model_type}/{name}.pth\")\n",
    "model.load_state_dict(nn_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(model, data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(model, data['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(model, data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class(model, data['test'], data['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, 4, data['test'], data['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
